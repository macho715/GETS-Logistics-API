"""
MACHO-GPT API Health Check Test Suite
HVDC Project - GETS Action API for ChatGPT
Mode: RHYTHM (Real-time KPI Monitoring)
"""

import pytest
import requests
import time
from datetime import datetime
from typing import Dict, List, Tuple

# API Base URL
API_BASE_URL = "https://gets-logistics-api.vercel.app"

# Performance SLA (MACHO-GPT Standards)
MAX_RESPONSE_TIME = 2.0  # seconds
MIN_CONFIDENCE = 0.90
SUCCESS_RATE_TARGET = 0.95


class TestAPIHealthCheck:
    """API Health Check Test Suite following TDD principles"""

    def test_api_root_endpoint_should_return_status(self):
        """
        RED â†’ GREEN: API í™ˆ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì˜¨ë¼ì¸ ìƒíƒœ ë°˜í™˜í•´ì•¼ í•¨
        """
        # Given: API base URL
        url = f"{API_BASE_URL}/"

        # When: GET ìš”ì²­ ì‹¤í–‰
        start_time = time.time()
        response = requests.get(url)
        response_time = time.time() - start_time

        # Then: ì„±ê³µ ì‘ë‹µ ë° ì„±ëŠ¥ ê²€ì¦
        assert response.status_code == 200, f"Expected 200, got {response.status_code}"
        assert response_time < MAX_RESPONSE_TIME, f"Response time {response_time:.2f}s exceeds SLA"

        data = response.json()
        assert data["status"] == "online", "API should be online"
        assert "version" in data, "Version info required"
        assert "endpoints" in data, "Endpoint list required"

        print(f"âœ… Root Endpoint: {response_time:.3f}s | Status: {data['status']}")

    def test_document_status_endpoint_should_return_shipment_data(self):
        """
        RED â†’ GREEN: ë¬¸ì„œ ìƒíƒœ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì„ ì  ì •ë³´ ë°˜í™˜í•´ì•¼ í•¨
        """
        # Given: í…ŒìŠ¤íŠ¸ìš© ì„ ì ë²ˆí˜¸
        test_shpt_no = "HVDC-ADOPT-SIM-0065"
        url = f"{API_BASE_URL}/document/status/{test_shpt_no}"

        # When: GET ìš”ì²­ ì‹¤í–‰
        start_time = time.time()
        response = requests.get(url)
        response_time = time.time() - start_time

        # Then: ë°ì´í„° êµ¬ì¡° ë° í•„ìˆ˜ í•„ë“œ ê²€ì¦
        assert response.status_code == 200, f"Expected 200, got {response.status_code}"
        assert response_time < MAX_RESPONSE_TIME, f"Response time {response_time:.2f}s exceeds SLA"

        data = response.json()
        required_fields = ["shptNo", "boeStatus", "doStatus", "cooReady", "hblReady", "ciplValid", "lastUpdated"]

        for field in required_fields:
            assert field in data, f"Required field '{field}' missing"

        assert data["shptNo"] == test_shpt_no, "Shipment number mismatch"

        print(f"âœ… Document Status: {response_time:.3f}s | ShptNo: {data['shptNo']}")

    def test_document_status_should_handle_different_shipment_numbers(self):
        """
        REFACTOR: ë‹¤ì–‘í•œ ì„ ì ë²ˆí˜¸ ì²˜ë¦¬ ê²€ì¦
        """
        # Given: ë‹¤ì–‘í•œ ì„ ì ë²ˆí˜¸ íŒ¨í„´
        test_cases = [
            "HVDC-ADOPT-SIM-0065",
            "HVDC-ADOPT-SCT-0041",
            "TEST-123-ABC-9999"
        ]

        for shpt_no in test_cases:
            # When: ê° ì„ ì ë²ˆí˜¸ë¡œ ìš”ì²­
            url = f"{API_BASE_URL}/document/status/{shpt_no}"
            response = requests.get(url)

            # Then: ì •ìƒ ì‘ë‹µ ë° ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
            assert response.status_code == 200
            data = response.json()
            assert data["shptNo"] == shpt_no

            print(f"âœ… Tested ShptNo: {shpt_no}")

    def test_status_summary_endpoint_should_return_kpi_metrics(self):
        """
        RED â†’ GREEN: ì „ì²´ í˜„í™© ì—”ë“œí¬ì¸íŠ¸ëŠ” KPI ì§€í‘œ ë°˜í™˜í•´ì•¼ í•¨
        Note: API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš” (401 ì˜ˆìƒ ê°€ëŠ¥)
        """
        # Given: ì „ì²´ í˜„í™© URL
        url = f"{API_BASE_URL}/status/summary"

        # When: GET ìš”ì²­ ì‹¤í–‰
        start_time = time.time()
        response = requests.get(url)
        response_time = time.time() - start_time

        # Then: ì‘ë‹µ ê²€ì¦ (ì¸ì¦ ì—†ìœ¼ë©´ 401 ì˜ˆìƒ)
        if response.status_code == 401:
            print(f"âš ï¸  Status Summary: 401 Unauthorized (API_KEY required)")
            pytest.skip("API_KEY not configured - skipping authentication test")

        assert response.status_code == 200, f"Expected 200, got {response.status_code}"
        assert response_time < MAX_RESPONSE_TIME, f"Response time {response_time:.2f}s exceeds SLA"

        data = response.json()
        required_kpi_fields = ["totalShipments", "ciplRate", "hblRate", "cooRate", "doRate", "boeRate"]

        for field in required_kpi_fields:
            assert field in data, f"KPI field '{field}' missing"
            if "Rate" in field:
                assert 0 <= data[field] <= 1, f"{field} should be between 0 and 1"

        print(f"âœ… Status Summary: {response_time:.3f}s | Total: {data['totalShipments']}")

    def test_api_performance_should_meet_sla(self):
        """
        Performance Critical: ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ëŠ” 2ì´ˆ ì´ë‚´ ì‘ë‹µ
        """
        # Given: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ì—”ë“œí¬ì¸íŠ¸
        endpoints = [
            "/",
            "/document/status/HVDC-ADOPT-SIM-0065"
        ]

        performance_results = []

        for endpoint in endpoints:
            # When: 5íšŒ ë°˜ë³µ ì¸¡ì •
            times = []
            for _ in range(5):
                start = time.time()
                response = requests.get(f"{API_BASE_URL}{endpoint}")
                elapsed = time.time() - start
                times.append(elapsed)

                # Then: ê° ìš”ì²­ì´ SLA ì¶©ì¡±
                assert response.status_code == 200
                assert elapsed < MAX_RESPONSE_TIME

            avg_time = sum(times) / len(times)
            max_time = max(times)
            min_time = min(times)

            performance_results.append({
                "endpoint": endpoint,
                "avg": avg_time,
                "max": max_time,
                "min": min_time
            })

            print(f"ğŸ“Š {endpoint}: avg={avg_time:.3f}s, max={max_time:.3f}s, min={min_time:.3f}s")

        # Verify: í‰ê·  ì‘ë‹µì‹œê°„ì´ SLA ì¤€ìˆ˜
        for result in performance_results:
            assert result["avg"] < MAX_RESPONSE_TIME

    def test_api_error_handling_should_be_graceful(self):
        """
        Error Handling: ì˜ëª»ëœ ìš”ì²­ì— ëŒ€í•œ ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬
        """
        # Given: ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤
        error_scenarios = [
            ("/document/status/", 404),  # ë¹ˆ ì„ ì ë²ˆí˜¸
            ("/nonexistent", 404),  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸
        ]

        for endpoint, expected_status in error_scenarios:
            # When: ì—ëŸ¬ ìœ ë°œ ìš”ì²­
            url = f"{API_BASE_URL}{endpoint}"
            response = requests.get(url)

            # Then: ì ì ˆí•œ ì˜¤ë¥˜ ì½”ë“œ ë°˜í™˜
            print(f"ğŸ” Error Test: {endpoint} â†’ {response.status_code}")
            # Note: 404ëŠ” Vercel ë¼ìš°íŒ…ì—ì„œ ì²˜ë¦¬ë  ìˆ˜ ìˆìŒ


def generate_health_check_report(results: List[Dict]) -> str:
    """
    Health Check ê²°ê³¼ë¥¼ MACHO-GPT í‘œì¤€ ë¦¬í¬íŠ¸ë¡œ ìƒì„±
    """
    timestamp = datetime.now().isoformat()

    report = f"""
# ğŸ¥ MACHO-GPT API Health Check Report
**Timestamp:** {timestamp}
**Mode:** RHYTHM (Real-time KPI Monitoring)
**Target:** {API_BASE_URL}

## ğŸ“Š Summary
- **Total Tests:** {len(results)}
- **Passed:** {sum(1 for r in results if r['status'] == 'PASS')}
- **Failed:** {sum(1 for r in results if r['status'] == 'FAIL')}
- **Success Rate:** {sum(1 for r in results if r['status'] == 'PASS') / len(results) * 100:.1f}%

## ğŸ¯ Endpoint Status
"""

    for result in results:
        status_icon = "âœ…" if result['status'] == 'PASS' else "âŒ"
        report += f"{status_icon} **{result['endpoint']}**: {result['response_time']:.3f}s\n"

    report += "\n---\n**MACHO-GPT v3.4-mini | Confidence: â‰¥0.95**"

    return report


if __name__ == "__main__":
    print("ğŸš€ Starting MACHO-GPT API Health Check...")
    print(f"Target: {API_BASE_URL}")
    print("=" * 60)

    # Run pytest with verbose output
    pytest.main([__file__, "-v", "--tb=short"])

