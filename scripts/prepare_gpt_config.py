#!/usr/bin/env python3
"""
GPTs ì„¤ì • ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸

GPTs ì„¤ì •ì— í•„ìš”í•œ ëª¨ë“  íŒŒì¼ì„ ê²€ì¦í•˜ê³ , ë³µì‚¬/ë¶™ì—¬ë„£ê¸°ìš© í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/prepare_gpt_config.py
    python scripts/prepare_gpt_config.py --output-dir ./gpt_config
    python scripts/prepare_gpt_config.py --validate-only
"""

from __future__ import annotations

import argparse
import json
import os
import re
import shutil
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple
from zoneinfo import ZoneInfo

import yaml

# Windows ì½˜ì†” UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == "win32":
    if hasattr(sys.stdout, "reconfigure"):
        sys.stdout.reconfigure(encoding="utf-8")
    if hasattr(sys.stderr, "reconfigure"):
        sys.stderr.reconfigure(encoding="utf-8")
    os.environ["PYTHONIOENCODING"] = "utf-8"

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

# íŒŒì¼ ê²½ë¡œ
BASE_DIR = Path(__file__).parent.parent
GUIDES_DIR = BASE_DIR / "docs" / "guides"
OPENAPI_DIR = BASE_DIR / "docs" / "openapi"

INSTRUCTIONS_FILE = GUIDES_DIR / "GPT_INSTRUCTIONS.md"
CONVERSATION_STARTERS_FILE = GUIDES_DIR / "GPT_CONVERSATION_STARTERS.md"
KNOWLEDGE_FILES = [
    GUIDES_DIR / "Excel_Batch_Upload_Workflow.md",
    GUIDES_DIR / "Common_Workflows.md",
    GUIDES_DIR / "API_Reference_Guide.md",
]
# NOTE: This script uses Airtable Direct API schema (v1.0.4).
# For GETS API with /shipments/verify endpoint, use: OPENAPI_DIR / "openapi-gets-api.yaml"
# The Airtable Direct API provides raw Airtable access, while GETS API includes business logic.
OPENAPI_SCHEMA_FILE = OPENAPI_DIR / "openapi-airtable-api-v1.0.4.yaml"

GPT_NAME = "GETS Logistics Assistant"
GPT_DESCRIPTION = "HVDC Project Logistics Assistant with real-time Airtable integration"

# GPT Builder UI ê´€ì¸¡ ê¸°ë°˜ ì œí•œê°’ (ìš´ì˜ ì‹œ ë³€ë™ ê°€ëŠ¥)
INSTRUCTIONS_MAX_LEN = 8000
MAX_KNOWLEDGE_FILES = 20
MAX_FILE_BYTES = 512 * 1024 * 1024  # 512MB
DUBAI_TZ = ZoneInfo("Asia/Dubai")


@dataclass(frozen=True)
class LimitCheck:
    ok: bool
    message: str


def load_file_content(file_path: Path) -> str:
    """íŒŒì¼ ë‚´ìš© ì½ê¸°"""
    if not file_path.exists():
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

    return file_path.read_text(encoding="utf-8").strip()


def parse_conversation_starters(file_path: Path) -> List[str]:
    """
    Conversation starters íŒŒì¼ì—ì„œ 4ê°œ ì¶”ì¶œ

    - ìš°ì„ : "ì¶”ì²œ ì„¸íŠ¸" / "Option A" ì„¹ì…˜ ì•„ë˜ ordered list(1. ~) ì¶”ì¶œ
    - í´ë°±: ë¬¸ì„œ ì „ì²´ì—ì„œ ordered list 1~4ë¥¼ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ
    - ìµœì¢… í´ë°±: ê¸°ë³¸ê°’ 4ê°œ
    """
    content = load_file_content(file_path)
    lines = content.splitlines()

    starters: List[str] = []
    in_section = False

    ordered_re = re.compile(r"^\s*(\d+)\.\s+(.*\S)\s*$")

    for line in lines:
        if "ì¶”ì²œ ì„¸íŠ¸" in line or "Option A" in line:
            in_section = True
            continue

        m = ordered_re.match(line)
        if in_section and m:
            num = int(m.group(1))
            if 1 <= num <= 10:
                starters.append(m.group(2).strip())

        if len(starters) >= 4:
            break

    if len(starters) < 4:
        starters = []
        for line in lines:
            m = ordered_re.match(line)
            if m:
                starters.append(m.group(2).strip())
            if len(starters) >= 4:
                break

    if len(starters) < 4:
        starters = [
            "ğŸ“Š í˜„ì¬ ë³‘ëª©(bottleneck) ìƒí™©ì„ ìš”ì•½í•´ì¤˜",
            "ğŸš¢ SCT-0143 ì„ ì  ìƒíƒœë¥¼ ìì„¸íˆ ë³´ì—¬ì¤˜",
            "â° D-5 ë˜ëŠ” ì´ˆê³¼ëœ ìŠ¹ì¸ ê±´ì´ ìˆì–´?",
            "ğŸ“ˆ ì˜¤ëŠ˜ì˜ KPI ëŒ€ì‹œë³´ë“œë¥¼ ë³´ì—¬ì¤˜",
        ]

    return starters[:4]


def validate_instructions(instructions: str) -> LimitCheck:
    """Instructions ê¸¸ì´ ê²€ì¦"""
    if len(instructions) > INSTRUCTIONS_MAX_LEN:
        return LimitCheck(
            False, f"âš ï¸ ì´ˆê³¼: {len(instructions)}ì (ìµœëŒ€ {INSTRUCTIONS_MAX_LEN}ì)"
        )
    return LimitCheck(
        True, f"âœ… {len(instructions)}ì ({INSTRUCTIONS_MAX_LEN}ì ì œí•œ ë‚´)"
    )


def validate_openapi_schema(file_path: Path) -> Tuple[bool, Dict[str, Any]]:
    """OpenAPI ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ìµœì†Œ ê²€ì¦)"""
    try:
        schema = yaml.safe_load(file_path.read_text(encoding="utf-8"))

        if not isinstance(schema, dict):
            return False, {"error": "ìŠ¤í‚¤ë§ˆ íŒŒì‹± ê²°ê³¼ê°€ dictê°€ ì•„ë‹™ë‹ˆë‹¤."}

        required_keys = ["openapi", "info", "paths"]
        missing = [key for key in required_keys if key not in schema]
        if missing:
            return False, {"error": f"í•„ìˆ˜ í‚¤ ëˆ„ë½: {missing}"}

        openapi_ver = str(schema.get("openapi", ""))
        if not openapi_ver.startswith("3."):
            return False, {"error": f"OpenAPI ë²„ì „ì´ 3.xê°€ ì•„ë‹™ë‹ˆë‹¤: {openapi_ver}"}

        return True, schema
    except Exception as e:
        return False, {"error": str(e)}


def check_knowledge_files() -> Dict[str, Any]:
    """Knowledge íŒŒì¼ í™•ì¸ + ì œí•œê°’ ê²½ê³ """
    result: Dict[str, Any] = {
        "total": len(KNOWLEDGE_FILES),
        "found": [],
        "missing": [],
        "over_limit": {
            "count_exceeded": False,
            "files_over_512mb": [],
        },
    }

    for file_path in KNOWLEDGE_FILES:
        if file_path.exists():
            size = file_path.stat().st_size
            entry = {"name": file_path.name, "path": str(file_path), "size": size}
            result["found"].append(entry)

            if size > MAX_FILE_BYTES:
                result["over_limit"]["files_over_512mb"].append(entry)
        else:
            result["missing"].append({"name": file_path.name, "path": str(file_path)})

    if result["total"] > MAX_KNOWLEDGE_FILES:
        result["over_limit"]["count_exceeded"] = True

    return result


def generate_setup_guide(
    instructions: str,
    conversation_starters: List[str],
    openapi_schema: Dict[str, Any],
    knowledge_files: Dict[str, Any],
) -> str:
    """GPTs ì„¤ì • ê°€ì´ë“œ ìƒì„±"""

    schema_info = (
        openapi_schema.get("info", {}) if isinstance(openapi_schema, dict) else {}
    )
    schema_title = schema_info.get("title", "N/A")
    schema_version = schema_info.get("version", "N/A")

    found_cnt = len(knowledge_files.get("found", []))
    total_cnt = knowledge_files.get("total", 0)
    generated_at = datetime.now(DUBAI_TZ).isoformat(timespec="seconds")

    guide = f"""# GETS Logistics GPT ì„¤ì • ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” ChatGPT GPT Builderì—ì„œ GPTsë¥¼ ì„¤ì •í•˜ëŠ” ë‹¨ê³„ë³„ ì•ˆë‚´ì…ë‹ˆë‹¤.

## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„

âœ… Instructions íŒŒì¼: {len(instructions)}ì
âœ… Conversation Starters: {len(conversation_starters)}ê°œ (Desktop ìµœì´ˆ 4ê°œ ë…¸ì¶œ ê¶Œì¥)
âœ… OpenAPI Schema: {schema_title} v{schema_version}
âœ… Knowledge Files: {total_cnt}ê°œ (ë°œê²¬: {found_cnt}ê°œ)

ì°¸ê³ : KnowledgeëŠ” GPTë‹¹ ìµœëŒ€ {MAX_KNOWLEDGE_FILES}ê°œ íŒŒì¼, íŒŒì¼ë‹¹ ìµœëŒ€ 512MB ì œí•œì´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸš€ ì„¤ì • ë‹¨ê³„

### Step 1: GPT ìƒì„±

1. ChatGPT â†’ Explore GPTs â†’ Create
2. Configure íƒ­
3. Name: **{GPT_NAME}**
4. Description: **{GPT_DESCRIPTION}**

---

### Step 2: Instructions ì„¤ì •

Instructions ì„¹ì…˜ì— ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ì „ì²´ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ê¸°:

---

## ğŸ“ Instructions (ì•„ë˜ ë‚´ìš© ë³µì‚¬)

```
{instructions}
```

---

### Step 3: Conversation Starters ì„¤ì •

1. "Conversation starters" ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤
2. ì•„ë˜ 4ê°œë¥¼ ê°ê° ì…ë ¥:

1. {conversation_starters[0]}
2. {conversation_starters[1]}
3. {conversation_starters[2]}
4. {conversation_starters[3]}

---

### Step 4: Actions ì„¤ì • (OpenAPI Schema)

1. "Actions" ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤
2. "Create new action" í´ë¦­
3. "Manual schema" ì„ íƒ (ë˜ëŠ” "Import from URL" ì‚¬ìš© ê°€ëŠ¥)

**ì˜µì…˜ A: Import from URL (ê¶Œì¥)**
```
https://gets-logistics-api.vercel.app/openapi-schema.yaml
```

**ì˜µì…˜ B: Manual Schema**
OpenAPI ìŠ¤í‚¤ë§ˆ íŒŒì¼ ìœ„ì¹˜: `{OPENAPI_SCHEMA_FILE}`
íŒŒì¼ ë‚´ìš©ì„ ì „ì²´ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ê¸°

4. **Authentication ì„¤ì •**:
   - Type: **Bearer**
   - Token: Airtable Personal Access Token ì…ë ¥
     - í† í° ë°œê¸‰: https://airtable.com/create/tokens
     - Scopes: `data.records:read`, `data.records:write`
     - Base: `appnLz06h07aMm366`

---

### Step 5: Knowledge Files ì—…ë¡œë“œ

1. "Knowledge" ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤
2. "Upload files" í´ë¦­
3. ë‹¤ìŒ íŒŒì¼ë“¤ì„ ì—…ë¡œë“œ:

"""

    for file_info in knowledge_files.get("found", []):
        guide += f"- `{file_info['name']}` ({file_info['size']:,} bytes)\n"

    if knowledge_files.get("missing"):
        guide += "\nâš ï¸ ë‹¤ìŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\n"
        for file_info in knowledge_files["missing"]:
            guide += f"- `{file_info['name']}`\n"

    guide += f"""
4. íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°

---

### Step 6: ì €ì¥ ë° í…ŒìŠ¤íŠ¸

1. "Save" ë²„íŠ¼ í´ë¦­ (ì˜¤ë¥¸ìª½ ìƒë‹¨)
2. Visibility ì„ íƒ:
   - **Only me** - ê°œì¸ìš©
   - **Anyone with a link** - ë§í¬ ê³µìœ 
   - **Public** - GPT Store ê³µê°œ

3. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬:
   - "í˜„ì¬ ë³‘ëª© ìƒí™©ì„ ìš”ì•½í•´ì¤˜"
   - "SCT-0143 ì„ ì  ìƒíƒœë¥¼ ë³´ì—¬ì¤˜"
   - "D-5 ì´ˆê³¼ ìŠ¹ì¸ ê±´ì´ ìˆì–´?"

---

## âœ… í™•ì¸ ì‚¬í•­

- [ ] Instructionsê°€ 8,000ì ì´ë‚´ì¸ì§€ í™•ì¸
- [ ] Conversation Starters 4ê°œ ì…ë ¥ í™•ì¸
- [ ] Actionsì—ì„œ OpenAPI Schema ë¡œë“œ í™•ì¸
- [ ] Authentication (Bearer Token) ì„¤ì • í™•ì¸
- [ ] Knowledge Files ì—…ë¡œë“œ ì™„ë£Œ í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„±ê³µ í™•ì¸

---

## ğŸ”— ì°¸ê³  ë§í¬

- **API Base URL**: https://gets-logistics-api.vercel.app
- **OpenAPI Schema URL**: https://gets-logistics-api.vercel.app/openapi-schema.yaml
- **Airtable Base ID**: appnLz06h07aMm366
- **Schema Version**: 2025-12-25T00:32:52+0400

---

**ìƒì„± ì¼ì‹œ**: {generated_at}
"""

    return guide


def save_config_files(
    output_dir: Path,
    instructions: str,
    conversation_starters: List[str],
    openapi_schema: Dict[str, Any],
    knowledge_files: Dict[str, Any],
) -> None:
    """ì„¤ì • íŒŒì¼ë“¤ì„ ì¶œë ¥ ë””ë ‰í† ë¦¬ì— ì €ì¥"""
    output_dir.mkdir(parents=True, exist_ok=True)

    # Instructions
    instructions_file = output_dir / "instructions.txt"
    instructions_file.write_text(instructions, encoding="utf-8")
    print(f"âœ… Instructions ì €ì¥: {instructions_file}")

    # Conversation Starters
    starters_file = output_dir / "conversation_starters.json"
    starters_data = {
        "starters": conversation_starters,
        "count": len(conversation_starters),
    }
    starters_file.write_text(
        json.dumps(starters_data, indent=2, ensure_ascii=False), encoding="utf-8"
    )
    print(f"âœ… Conversation Starters ì €ì¥: {starters_file}")

    # OpenAPI Schema
    schema_file = output_dir / "openapi-schema.yaml"
    with open(schema_file, "w", encoding="utf-8") as f:
        yaml.dump(openapi_schema, f, allow_unicode=True, sort_keys=False)
    print(f"âœ… OpenAPI Schema ì €ì¥: {schema_file}")

    # Knowledge Files ë³µì‚¬
    knowledge_dir = output_dir / "knowledge"
    knowledge_dir.mkdir(exist_ok=True)

    for file_info in knowledge_files.get("found", []):
        src = Path(file_info["path"])
        dst = knowledge_dir / file_info["name"]
        shutil.copy2(src, dst)
        print(f"âœ… Knowledge íŒŒì¼ ë³µì‚¬: {dst}")

    # ì„¤ì • ê°€ì´ë“œ
    guide = generate_setup_guide(
        instructions, conversation_starters, openapi_schema, knowledge_files
    )
    guide_file = output_dir / "SETUP_GUIDE.md"
    guide_file.write_text(guide, encoding="utf-8")
    print(f"âœ… ì„¤ì • ê°€ì´ë“œ ì €ì¥: {guide_file}")

    # ìš”ì•½ JSON
    summary = {
        "gpt_name": GPT_NAME,
        "gpt_description": GPT_DESCRIPTION,
        "instructions_length": len(instructions),
        "instructions_valid": len(instructions) <= INSTRUCTIONS_MAX_LEN,
        "conversation_starters_count": len(conversation_starters),
        "openapi_schema": {
            "title": (
                openapi_schema.get("info", {}).get("title", "N/A")
                if isinstance(openapi_schema, dict)
                else "N/A"
            ),
            "version": (
                openapi_schema.get("info", {}).get("version", "N/A")
                if isinstance(openapi_schema, dict)
                else "N/A"
            ),
        },
        "knowledge_files": {
            "total": knowledge_files.get("total", 0),
            "found": len(knowledge_files.get("found", [])),
            "missing": len(knowledge_files.get("missing", [])),
            "over_limit": knowledge_files.get("over_limit", {}),
        },
        "generated_at": datetime.now(DUBAI_TZ).isoformat(timespec="seconds"),
    }
    summary_file = output_dir / "summary.json"
    summary_file.write_text(
        json.dumps(summary, indent=2, ensure_ascii=False), encoding="utf-8"
    )
    print(f"âœ… ìš”ì•½ ì €ì¥: {summary_file}")


def main() -> None:
    parser = argparse.ArgumentParser(description="GPTs ì„¤ì • íŒŒì¼ ì¤€ë¹„ ë° ê²€ì¦")
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì½˜ì†” ì¶œë ¥ë§Œ)",
    )
    parser.add_argument(
        "--validate-only",
        action="store_true",
        help="ê²€ì¦ë§Œ ìˆ˜í–‰ (íŒŒì¼ ì €ì¥ ì•ˆ í•¨)",
    )

    args = parser.parse_args()

    print("ğŸ” GPTs ì„¤ì • íŒŒì¼ ê²€ì¦ ì¤‘...\n")

    # íŒŒì¼ ë¡œë“œ ë° ê²€ì¦
    errors = []
    warnings = []

    try:
        # Instructions
        print("ğŸ“ Instructions ê²€ì¦ ì¤‘...")
        instructions = load_file_content(INSTRUCTIONS_FILE)
        check = validate_instructions(instructions)
        print(f"   {check.message}")
        if not check.ok:
            warnings.append(f"Instructions: {check.message}")

        # Conversation Starters
        print("\nğŸ’¬ Conversation Starters ê²€ì¦ ì¤‘...")
        conversation_starters = parse_conversation_starters(CONVERSATION_STARTERS_FILE)
        print(f"   âœ… {len(conversation_starters)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        for i, starter in enumerate(conversation_starters, 1):
            print(f"      {i}. {starter[:50]}...")

        # OpenAPI Schema
        print("\nğŸ“‹ OpenAPI Schema ê²€ì¦ ì¤‘...")
        valid, schema_result = validate_openapi_schema(OPENAPI_SCHEMA_FILE)
        if valid:
            schema_info = schema_result.get("info", {})
            print("   âœ… ìœ íš¨í•œ OpenAPI ìŠ¤í‚¤ë§ˆ")
            print(f"      Title: {schema_info.get('title', 'N/A')}")
            print(f"      Version: {schema_info.get('version', 'N/A')}")
            openapi_schema = schema_result
        else:
            print(f"   âŒ ê²€ì¦ ì‹¤íŒ¨: {schema_result.get('error', 'Unknown error')}")
            errors.append(
                f"OpenAPI Schema: {schema_result.get('error', 'Unknown error')}"
            )
            openapi_schema = {}

        # Knowledge Files
        print("\nğŸ“š Knowledge Files í™•ì¸ ì¤‘...")
        knowledge_files = check_knowledge_files()
        print(f"   ë°œê²¬: {len(knowledge_files['found'])}/{knowledge_files['total']}ê°œ")
        for file_info in knowledge_files["found"]:
            print(f"      âœ… {file_info['name']} ({file_info['size']:,} bytes)")
        for file_info in knowledge_files["missing"]:
            print(f"      âŒ {file_info['name']} (íŒŒì¼ ì—†ìŒ)")
            warnings.append(f"Knowledge íŒŒì¼ ëˆ„ë½: {file_info['name']}")

        # í¬ê¸° ì œí•œ ê²½ê³ 
        if knowledge_files["over_limit"]["files_over_512mb"]:
            for file_info in knowledge_files["over_limit"]["files_over_512mb"]:
                size_mb = file_info["size"] / (1024 * 1024)
                warnings.append(
                    f"Knowledge íŒŒì¼ ì´ˆê³¼: {file_info['name']} ({size_mb:.1f}MB > 512MB)"
                )

    except Exception as e:
        print(f"\nâŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # ê²€ì¦ ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    if errors:
        print(f"\nâŒ ì˜¤ë¥˜: {len(errors)}ê°œ")
        for error in errors:
            print(f"   - {error}")

    if warnings:
        print(f"\nâš ï¸ ê²½ê³ : {len(warnings)}ê°œ")
        for warning in warnings:
            print(f"   - {warning}")

    if not errors and not warnings:
        print("\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼!")

    # íŒŒì¼ ì €ì¥ (--validate-onlyê°€ ì•„ë‹ ë•Œ)
    if not args.validate_only:
        if args.output_dir:
            output_dir = Path(args.output_dir)
            print(f"\nğŸ’¾ ì„¤ì • íŒŒì¼ ì €ì¥ ì¤‘: {output_dir}")
            save_config_files(
                output_dir,
                instructions,
                conversation_starters,
                openapi_schema,
                knowledge_files,
            )
            print(f"\nâœ… ëª¨ë“  íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_dir}")
        else:
            # ì½˜ì†”ì— ì„¤ì • ê°€ì´ë“œ ì¶œë ¥
            print("\n" + "=" * 60)
            print("ğŸ“‹ GPTs ì„¤ì • ê°€ì´ë“œ")
            print("=" * 60)
            guide = generate_setup_guide(
                instructions, conversation_starters, openapi_schema, knowledge_files
            )
            print(guide)

            print("\nğŸ’¡ íŒŒì¼ë¡œ ì €ì¥í•˜ë ¤ë©´: --output-dir ./gpt_config")


if __name__ == "__main__":
    main()
