"""
ChatGPTê°€ ì¤€ë¹„í•œ JSON ë°ì´í„°ë¥¼ Airtable Shipments í…Œì´ë¸”ì— ì—…ë¡œë“œ

ì‚¬ìš©ë²•:
    python scripts/upload_shipments_to_airtable.py \
        --file chatgpt_prepared_data_v14.json \
        --token pat_xxxxxxxxxxxxx
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from api.airtable_client import AirtableClient
from api.airtable_locked_config import BASE_ID, TABLES, PROTECTED_FIELDS
from api.utils import parse_iso_any, iso_dubai, DUBAI_TZ

def normalize_datetime_field(value: Any) -> Optional[str]:
    """ë‚ ì§œ/ì‹œê°„ í•„ë“œë¥¼ Airtable í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
    if value is None:
        return None

    # pandas NaT ì²˜ë¦¬
    if isinstance(value, str) and value in ["NaT", "nan", "NaN"]:
        return None

    # float NaN ì²˜ë¦¬
    if isinstance(value, float) and str(value) == "nan":
        return None

    if isinstance(value, str):
        # ISO í˜•ì‹ì´ë©´ íŒŒì‹±
        if "T" in value or "-" in value:
            dt = parse_iso_any(value)
            if dt:
                return iso_dubai(dt)
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê·¸ëŒ€ë¡œ ë°˜í™˜ (Airtable typecastê°€ ì²˜ë¦¬)
            return value

    # datetime ê°ì²´ë©´ ë³€í™˜
    if isinstance(value, datetime):
        return iso_dubai(value.astimezone(DUBAI_TZ))

    return str(value) if value else None

def prepare_airtable_record(record: Dict[str, Any]) -> Dict[str, Any]:
    """ChatGPT JSON ë ˆì½”ë“œë¥¼ Airtable í•„ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    # Protected Fieldsë§Œ ì¶”ì¶œ (í•„ìˆ˜ í•„ë“œ)
    protected = PROTECTED_FIELDS["Shipments"]

    airtable_record = {}

    # shptNoëŠ” í•„ìˆ˜ (upsert ê¸°ì¤€)
    if "shptNo" not in record:
        raise ValueError(f"ë ˆì½”ë“œì— shptNoê°€ ì—†ìŠµë‹ˆë‹¤: {list(record.keys())}")

    shpt_no = record["shptNo"]
    if not shpt_no or str(shpt_no).strip() == "":
        raise ValueError(f"shptNoê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {record}")

    airtable_record["shptNo"] = str(shpt_no).strip()

    # Protected Fields ì²˜ë¦¬
    for field in protected:
        if field in record:
            value = record[field]

            # ë‚ ì§œ í•„ë“œ ì •ê·œí™”
            if field in ["bottleneckSince", "dueAt"]:
                normalized = normalize_datetime_field(value)
                if normalized:
                    airtable_record[field] = normalized
            else:
                # ë¬¸ìì—´ í•„ë“œëŠ” None/NaN ì²˜ë¦¬
                if value is None or (isinstance(value, float) and str(value) == "nan"):
                    continue
                if isinstance(value, str) and value in ["NaT", "nan", "NaN"]:
                    continue
                airtable_record[field] = str(value).strip() if isinstance(value, str) else value

    # ë©”íƒ€ë°ì´í„° í•„ë“œëŠ” ì œì™¸ (Airtableì— ì €ì¥í•˜ì§€ ì•ŠìŒ)
    excluded_fields = ["sourceFile", "generatedBy", "generatedAt",
                      "Normalized Shipment ID", "Normalized_No"]

    # ì„ íƒì  í•„ë“œ ì¶”ê°€ (remarks ë“±)
    for key, value in record.items():
        if key not in excluded_fields and key not in airtable_record:
            if value is not None and not (isinstance(value, float) and str(value) == "nan"):
                if isinstance(value, str) and value not in ["NaT", "nan", "NaN"]:
                    airtable_record[key] = value.strip() if isinstance(value, str) else value

    return airtable_record

def upload_shipments(
    records: List[Dict[str, Any]],
    api_token: str,
    dry_run: bool = False
) -> Dict[str, Any]:
    """
    Shipments ë ˆì½”ë“œë¥¼ Airtableì— Upsert

    Args:
        records: ChatGPTê°€ ì¤€ë¹„í•œ JSON ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸
        api_token: Airtable Personal Access Token
        dry_run: Trueë©´ ì‹¤ì œ ì—…ë¡œë“œ ì—†ì´ ê²€ì¦ë§Œ

    Returns:
        ì—…ë¡œë“œ ê²°ê³¼ í†µê³„
    """
    if not api_token:
        raise ValueError("AIRTABLE_API_TOKENì´ í•„ìš”í•©ë‹ˆë‹¤")

    # Airtable í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = AirtableClient(api_token.strip(), BASE_ID)
    table_id = TABLES["Shipments"]

    # ë ˆì½”ë“œ ì¤€ë¹„
    print(f"ğŸ“¦ {len(records)}ê°œ ë ˆì½”ë“œ ì¤€ë¹„ ì¤‘...")
    prepared_records = []
    errors = []

    for i, record in enumerate(records, 1):
        try:
            prepared = prepare_airtable_record(record)
            prepared_records.append(prepared)
        except Exception as e:
            error_msg = f"ë ˆì½”ë“œ {i} ë³€í™˜ ì‹¤íŒ¨: {e}"
            errors.append(error_msg)
            print(f"âš ï¸ {error_msg}")
            continue

    print(f"âœ… {len(prepared_records)}ê°œ ë ˆì½”ë“œ ì¤€ë¹„ ì™„ë£Œ")
    if errors:
        print(f"âš ï¸ {len(errors)}ê°œ ë ˆì½”ë“œ ë³€í™˜ ì‹¤íŒ¨")

    if dry_run:
        print("\nğŸ” DRY RUN ëª¨ë“œ - ì‹¤ì œ ì—…ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        print(f"   ì¤€ë¹„ëœ ë ˆì½”ë“œ ìƒ˜í”Œ (ì²« 3ê°œ):")
        for i, rec in enumerate(prepared_records[:3], 1):
            print(f"   {i}. {json.dumps(rec, indent=2, ensure_ascii=False)}")
        return {
            "status": "dry_run",
            "total_records": len(records),
            "prepared_records": len(prepared_records),
            "errors": len(errors),
            "batches": (len(prepared_records) + 9) // 10,
        }

    if not prepared_records:
        raise ValueError("ì—…ë¡œë“œí•  ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤")

    # Upsert ì‹¤í–‰
    print(f"\nğŸš€ Airtableì— ì—…ë¡œë“œ ì¤‘...")
    print(f"   í…Œì´ë¸”: Shipments ({table_id})")
    print(f"   ê¸°ì¤€ í•„ë“œ: shptNo (Protected Field)")
    print(f"   ë°°ì¹˜ í¬ê¸°: 10 ë ˆì½”ë“œ/ìš”ì²­")
    print()

    results = client.upsert_records(
        table_id,
        prepared_records,
        fields_to_merge_on=["shptNo"],  # Protected Field
        typecast=True,
    )

    # ê²°ê³¼ ì§‘ê³„
    total_uploaded = 0
    upload_errors = []

    for batch_idx, batch_result in enumerate(results, 1):
        if "records" in batch_result:
            total_uploaded += len(batch_result["records"])
        elif "error" in batch_result:
            error_info = batch_result.get("error", {})
            error_msg = error_info.get("message", str(batch_result))
            upload_errors.append(f"ë°°ì¹˜ {batch_idx}: {error_msg}")

    return {
        "status": "success" if not upload_errors else "partial",
        "total_records": len(records),
        "prepared_records": len(prepared_records),
        "batches": len(results),
        "uploaded": total_uploaded,
        "errors": errors + upload_errors,
        "schemaVersion": "2025-12-25T00:32:52+0400",
    }

def main():
    parser = argparse.ArgumentParser(
        description="ChatGPT JSON ë°ì´í„°ë¥¼ Airtableì— ì—…ë¡œë“œ"
    )
    parser.add_argument(
        "--file",
        type=str,
        default="chatgpt_prepared_data_v14.json",
        help="ChatGPTê°€ ìƒì„±í•œ JSON íŒŒì¼ ê²½ë¡œ",
    )
    parser.add_argument(
        "--token",
        type=str,
        default=None,
        help="Airtable Personal Access Token (ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤ì œ ì—…ë¡œë“œ ì—†ì´ ê²€ì¦ë§Œ ìˆ˜í–‰",
    )

    args = parser.parse_args()

    # JSON íŒŒì¼ ì½ê¸°
    json_path = Path(args.file)
    if not json_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
        print(f"   í˜„ì¬ ë””ë ‰í† ë¦¬: {Path.cwd()}")
        sys.exit(1)

    print(f"ğŸ“– JSON íŒŒì¼ ì½ê¸°: {json_path}")
    with open(json_path, "r", encoding="utf-8") as f:
        records = json.load(f)

    print(f"âœ… {len(records)}ê°œ ë ˆì½”ë“œ ë¡œë“œ ì™„ë£Œ\n")

    # API í† í° í™•ì¸
    api_token = args.token or os.getenv("AIRTABLE_API_TOKEN")
    if not api_token:
        print("âŒ AIRTABLE_API_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:")
        print("   1. --token íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬")
        print("   2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: export AIRTABLE_API_TOKEN=pat...")
        sys.exit(1)

    # ì—…ë¡œë“œ ì‹¤í–‰
    try:
        result = upload_shipments(records, api_token, dry_run=args.dry_run)

        print("\n" + "="*60)
        print("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
        print("="*60)
        print(json.dumps(result, indent=2, ensure_ascii=False))

        if result.get("status") == "success":
            print(f"\nğŸ“Š ìš”ì•½:")
            print(f"   ì´ ë ˆì½”ë“œ: {result['total_records']}ê°œ")
            print(f"   ì¤€ë¹„ëœ ë ˆì½”ë“œ: {result['prepared_records']}ê°œ")
            print(f"   ë°°ì¹˜ ìˆ˜: {result['batches']}ê°œ")
            print(f"   ì—…ë¡œë“œëœ ë ˆì½”ë“œ: {result['uploaded']}ê°œ")

            if result.get("errors"):
                print(f"\nâš ï¸ ê²½ê³ :")
                for err in result["errors"][:5]:
                    print(f"   - {err}")

            # ê²€ì¦ìš© API í˜¸ì¶œ ì•ˆë‚´
            print(f"\nğŸ” ì—…ë¡œë“œ ê²€ì¦:")
            print(f"   curl https://gets-logistics-api.vercel.app/status/summary")
            print(f"   curl https://gets-logistics-api.vercel.app/document/status/{{shptNo}}")

    except Exception as e:
        print(f"\nâŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()

